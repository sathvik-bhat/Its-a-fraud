# -*- coding: utf-8 -*-
"""LR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KMAnr7t6_82g1Fp8oGPs-2fs-rOp3EVX
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

main_df = pd.read_parquet("preprocessed_df.parquet")
X_test = pd.read_csv("../test.csv")

print(X_test.shape)

X_train = main_df.drop("isFraud", axis = 1)
Y_train = main_df["isFraud"]

# One hot encoding the categorical columns
categorical = X_test.select_dtypes(include = 'object').columns
# Filling missing values in categorical columns with mode value
X_test[categorical] = X_test[categorical].fillna(X_test[categorical].mode().iloc[0])
X_test = pd.get_dummies(X_test, columns = categorical)
X_test.shape
print(X_test.shape)

# Only selecting columns which are present in preprocessed data
X_test = pd.DataFrame(X_test, columns=X_train.columns)
print(X_test.shape)

# Filling the null values with mean
numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
numerical = X_test.select_dtypes(include = numerics).columns
X_test[numerical] = X_test[numerical].fillna(X_test[numerical].mean())

# Checking if any null value still exists
for i in X_test.columns:
  if X_test[i].isnull().sum()>0:
    print(i)

# Standardising the data
cols = X_test.select_dtypes(include=np.number).columns  
for i in cols:
    X_test[i] = (X_test[i] - X_test[i].mean())/X_test[i].std()

# Hyperparameter tuning using RamdonizedSearchCv
from scipy.stats import loguniform
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import LogisticRegression
# define evaluation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# define search space
space = dict()
space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']
# space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']
space['C'] = [100, 10, 1.0, 0.1, 0.01]
# define search
search = RandomizedSearchCV(LogisticRegression(), space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)
# execute search
result = search.fit(X_train, Y_train)
# summarize result
print('Best Score: %s' % result.best_score_)
print('Best Hyperparameters: %s' % result.best_params_)

# Using the parameters found above
classifier = LogisticRegression(random_state = 42, max_iter=200, C=0.01, solver="lbfgs")

# Calculating the output column 
y_pred = classifier.predict(X_test)

y_pred = pd.DataFrame(y_pred, columns=["isFraud"])
y_pred.to_csv("../csv/Y_predict_LR.csv", index=True, index_label=["Id"])